
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass{article}

    
    
    \usepackage{graphicx} % Used to insert images
    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{color} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    

    
    
    \definecolor{orange}{cmyk}{0,0.4,0.8,0.2}
    \definecolor{darkorange}{rgb}{.71,0.21,0.01}
    \definecolor{darkgreen}{rgb}{.12,.54,.11}
    \definecolor{myteal}{rgb}{.26, .44, .56}
    \definecolor{gray}{gray}{0.45}
    \definecolor{lightgray}{gray}{.95}
    \definecolor{mediumgray}{gray}{.8}
    \definecolor{inputbackground}{rgb}{.95, .95, .85}
    \definecolor{outputbackground}{rgb}{.95, .95, .95}
    \definecolor{traceback}{rgb}{1, .95, .95}
    % ansi colors
    \definecolor{red}{rgb}{.6,0,0}
    \definecolor{green}{rgb}{0,.65,0}
    \definecolor{brown}{rgb}{0.6,0.6,0}
    \definecolor{blue}{rgb}{0,.145,.698}
    \definecolor{purple}{rgb}{.698,.145,.698}
    \definecolor{cyan}{rgb}{0,.698,.698}
    \definecolor{lightgray}{gray}{0.5}
    
    % bright ansi colors
    \definecolor{darkgray}{gray}{0.25}
    \definecolor{lightred}{rgb}{1.0,0.39,0.28}
    \definecolor{lightgreen}{rgb}{0.48,0.99,0.0}
    \definecolor{lightblue}{rgb}{0.53,0.81,0.92}
    \definecolor{lightpurple}{rgb}{0.87,0.63,0.87}
    \definecolor{lightcyan}{rgb}{0.5,1.0,0.83}
    
    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{ML HW 1}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=blue,
      linkcolor=darkorange,
      citecolor=darkgreen,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Machine Learning Homework 1: Ridge Regression and
SGD}\label{machine-learning-homework-1-ridge-regression-and-sgd}

Due Friday, Feb 6 2015

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c}{\PYZsh{}Imports and load data}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{logging}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{sys}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} \PY{n}{inline}
        \PY{k+kn}{import} \PY{n+nn}{timeit}
        \PY{k+kn}{from} \PY{n+nn}{IPython.display} \PY{k+kn}{import} \PY{n}{Image}
        
        \PY{c}{\PYZsh{}Loading the dataset}
        \PY{k}{print}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{loading the dataset}\PY{l+s}{\PYZsq{}}\PY{p}{)}
        
        \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{hw1\PYZhy{}data.csv}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{delimiter}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{,}\PY{l+s}{\PYZsq{}}\PY{p}{)}
        \PY{n}{X} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{y} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
        
        \PY{k}{print}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Split into Train and Test}\PY{l+s}{\PYZsq{}}\PY{p}{)}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
loading the dataset
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------
    IOError                                   Traceback (most recent call last)

        <ipython-input-1-8054a86a933a> in <module>()
         14 print('loading the dataset')
         15 
    ---> 16 df = pd.read\_csv('hw1-data.csv', delimiter=',')
         17 X = df.values[:,:-1]
         18 y = df.values[:,-1]


        /Users/205341/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc in parser\_f(filepath\_or\_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index\_col, names, prefix, skiprows, skipfooter, skip\_footer, na\_values, na\_fvalues, true\_values, false\_values, delimiter, converters, dtype, usecols, engine, delim\_whitespace, as\_recarray, na\_filter, compact\_ints, use\_unsigned, low\_memory, buffer\_lines, warn\_bad\_lines, error\_bad\_lines, keep\_default\_na, thousands, comment, decimal, parse\_dates, keep\_date\_col, dayfirst, date\_parser, memory\_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle\_dupe\_cols, tupleize\_cols, infer\_datetime\_format)
        441                     infer\_datetime\_format=infer\_datetime\_format)
        442 
    --> 443         return \_read(filepath\_or\_buffer, kwds)
        444 
        445     parser\_f.\_\_name\_\_ = name


        /Users/205341/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc in \_read(filepath\_or\_buffer, kwds)
        226 
        227     \# Create the parser.
    --> 228     parser = TextFileReader(filepath\_or\_buffer, **kwds)
        229 
        230     if nrows is not None:


        /Users/205341/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc in \_\_init\_\_(self, f, engine, **kwds)
        531             self.options['has\_index\_names'] = kwds['has\_index\_names']
        532 
    --> 533         self.\_make\_engine(self.engine)
        534 
        535     def \_get\_options\_with\_defaults(self, engine):


        /Users/205341/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc in \_make\_engine(self, engine)
        668     def \_make\_engine(self, engine='c'):
        669         if engine == 'c':
    --> 670             self.\_engine = CParserWrapper(self.f, **self.options)
        671         else:
        672             if engine == 'python':


        /Users/205341/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc in \_\_init\_\_(self, src, **kwds)
       1030         kwds['allow\_leading\_cols'] = self.index\_col is not False
       1031 
    -> 1032         self.\_reader = \_parser.TextReader(src, **kwds)
       1033 
       1034         \# XXX


        /Users/205341/anaconda/lib/python2.7/site-packages/pandas/parser.so in pandas.parser.TextReader.\_\_cinit\_\_ (pandas/parser.c:3213)()


        /Users/205341/anaconda/lib/python2.7/site-packages/pandas/parser.so in pandas.parser.TextReader.\_setup\_parser\_source (pandas/parser.c:5595)()


        IOError: File hw1-data.csv does not exist

    \end{Verbatim}

    \subsubsection{2.1 Feature Normalization}\label{feature-normalization}

Modify function \texttt{feature\_normalization} to normalize all the
features to {[}0,1{]}. (Can you use numpy's ``broadcasting'' here?)

\begin{quote}
Numpy's broadcasting would be used here if train and test were different
sizes. We are broadcasting training arrays on the test set.
\end{quote}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}99}]:} \PY{k}{def} \PY{n+nf}{feature\PYZus{}normalization}\PY{p}{(}\PY{n}{train}\PY{p}{,} \PY{n}{test}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Rescale the data so that each feature in the training set is in}
         \PY{l+s+sd}{    the interval [0,1], and apply the same transformations to the test}
         \PY{l+s+sd}{    set, using the statistics computed on the training set.}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Args:}
         \PY{l+s+sd}{        train \PYZhy{} training set, a 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
         \PY{l+s+sd}{        test  \PYZhy{} test set, a 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
         \PY{l+s+sd}{    Returns:}
         \PY{l+s+sd}{        train\PYZus{}normalized \PYZhy{} training set after normalization}
         \PY{l+s+sd}{        test\PYZus{}normalized  \PYZhy{} test set after normalization}
         
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}    
         
             \PY{n}{train\PYZus{}range} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{ptp}\PY{p}{(}\PY{n}{train}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{train\PYZus{}range}\PY{p}{[}\PY{n}{train\PYZus{}range}\PY{o}{==}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{=}\PY{l+m+mi}{1}
             \PY{n}{train\PYZus{}min} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{n}{train}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{train\PYZus{}norm} \PY{o}{=} \PY{p}{(}\PY{n}{train} \PY{o}{\PYZhy{}} \PY{n}{train\PYZus{}min}\PY{p}{)}\PY{o}{/}\PY{n}{train\PYZus{}range}
             \PY{n}{test\PYZus{}norm} \PY{o}{=} \PY{p}{(}\PY{n}{test} \PY{o}{\PYZhy{}} \PY{n}{train\PYZus{}min}\PY{p}{)}\PY{o}{/}\PY{n}{train\PYZus{}range}
         
             \PY{k}{return} \PY{n}{train\PYZus{}norm}\PY{p}{,}\PY{n}{test\PYZus{}norm}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Scaling all to [0, 1]}\PY{l+s}{\PYZdq{}}\PY{p}{)}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{feature\PYZus{}normalization}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{)}    
         \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{hstack}\PY{p}{(}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{c}{\PYZsh{}Add bias term}
         \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{hstack}\PY{p}{(}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{c}{\PYZsh{}Add bias term}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Scaling all to [0, 1]
    \end{Verbatim}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{2.2 Gradient Descent Setup}\label{gradient-descent-setup}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write the objective function \(J(\theta)\) as a matrix/vector
  expression, without using an explicit summation
  sign.\\\textgreater{}\(J(\theta)=\frac{1}{2m}(X\theta - y)^T(X\theta - y)\)
\item
  Write down an expression for the gradient of \(J\).
  \textgreater{}\(\nabla J(\theta) = \frac{1}{m}(X\theta - y)^TX\)
\item
  Use the gradient to write down an approximate expression for
  \(J(\theta + \eta \Delta)-J(\theta)\) \textgreater{}\$J(\theta +
  \eta \Delta)-J(\theta) \approx \nabla J(\theta) \Delta \eta \$
\item
  Write down the expression for updating \(\theta\) in the gradient
  descent algorithm. Let \(\eta\) be the step
  size.\\\textgreater{}\(\theta_{i+1} = \theta_i - \eta * \nabla J(\theta)\)
\item
  Modify the function \texttt{compute\_square\_loss}, to compute
  \(J(\theta)\) for a given \(\theta\). \textgreater{}See next cell
\item
  Modify the function \texttt{compute\_square\_loss\_gradient}, to
  compute \(\nabla J(\theta)\)
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}Q2.2a: The square loss function}
        
        \PY{k}{def} \PY{n+nf}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{theta}\PY{p}{,} \PY{n}{lambda\PYZus{}reg}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Given a set of X, y, theta, compute the square loss for predicting y with X*theta}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        X \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
        \PY{l+s+sd}{        y \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
        \PY{l+s+sd}{        theta \PYZhy{} the parameter vector, 1D array of size (num\PYZus{}features)}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Returns:}
        \PY{l+s+sd}{        loss \PYZhy{} the square loss, scalar}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{loss} \PY{o}{=} \PY{l+m+mi}{0} \PY{c}{\PYZsh{}initialize the square\PYZus{}loss}
            \PY{n}{m}\PY{o}{=}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
            \PY{n}{yhat} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
            \PY{n}{loss} \PY{o}{=} \PY{l+m+mf}{1.0}\PY{o}{/}\PY{l+m+mi}{2}\PY{o}{/}\PY{n}{m} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{yhat}\PY{o}{\PYZhy{}}\PY{n}{y}\PY{p}{,}\PY{n}{yhat}\PY{o}{\PYZhy{}}\PY{n}{y}\PY{p}{)} \PY{o}{+} \PY{n}{lambda\PYZus{}reg}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{theta}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
            \PY{k}{return} \PY{n}{loss}
        
        
        \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}Q2.2b: compute the gradient of square loss function}
        \PY{k}{def} \PY{n+nf}{compute\PYZus{}square\PYZus{}loss\PYZus{}gradient}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{theta}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Compute gradient of the square loss (as defined in compute\PYZus{}square\PYZus{}loss), at the point theta.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        X \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
        \PY{l+s+sd}{        y \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
        \PY{l+s+sd}{        theta \PYZhy{} the parameter vector, 1D numpy array of size (num\PYZus{}features)}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Returns:}
        \PY{l+s+sd}{        grad \PYZhy{} gradient vector, 1D numpy array of size (num\PYZus{}features)}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{m}\PY{o}{=}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
            \PY{n}{yhat} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
            \PY{n}{grad} \PY{o}{=} \PY{l+m+mf}{1.0}\PY{o}{/}\PY{n}{m} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{yhat} \PY{o}{\PYZhy{}} \PY{n}{y}\PY{p}{,}\PY{n}{X}\PY{p}{)}
            \PY{k}{return} \PY{n}{grad}
\end{Verbatim}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{2.3 Gradient Checker}\label{gradient-checker}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Complete the function \texttt{grad\_checker} according to the
  documentation given.
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k}{def} \PY{n+nf}{grad\PYZus{}checker}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{theta}\PY{p}{,} \PY{n}{epsilon}\PY{o}{=}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{n}{tolerance}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{)}\PY{p}{:} 
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Implement Gradient Checker}
        \PY{l+s+sd}{    Check that the function compute\PYZus{}square\PYZus{}loss\PYZus{}gradient returns the}
        \PY{l+s+sd}{    correct gradient for the given X, y, and theta.}
        
        \PY{l+s+sd}{    Let d be the number of features. Here we numerically estimate the}
        \PY{l+s+sd}{    gradient by approximating the directional derivative in each of}
        \PY{l+s+sd}{    the d coordinate directions: }
        \PY{l+s+sd}{    (e\PYZus{}1 = (1,0,0,...,0), e\PYZus{}2 = (0,1,0,...,0), ..., e\PYZus{}d = (0,...,0,1) }
        
        \PY{l+s+sd}{    The approximation for the directional derivative of J at the point}
        \PY{l+s+sd}{    theta in the direction e\PYZus{}i is given by: }
        \PY{l+s+sd}{    ( J(theta + epsilon * e\PYZus{}i) \PYZhy{} J(theta \PYZhy{} epsilon * e\PYZus{}i) ) / (2*epsilon).}
        
        \PY{l+s+sd}{    We then look at the Euclidean distance between the gradient}
        \PY{l+s+sd}{    computed using this approximation and the gradient computed by}
        \PY{l+s+sd}{    compute\PYZus{}square\PYZus{}loss\PYZus{}gradient(X, y, theta).  If the Euclidean}
        \PY{l+s+sd}{    distance exceeds tolerance, we say the gradient is incorrect.}
        
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        X \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
        \PY{l+s+sd}{        y \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
        \PY{l+s+sd}{        theta \PYZhy{} the parameter vector, 1D numpy array of size (num\PYZus{}features)}
        \PY{l+s+sd}{        epsilon \PYZhy{} the epsilon used in approximation}
        \PY{l+s+sd}{        tolerance \PYZhy{} the tolerance error}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Return:}
        \PY{l+s+sd}{        A boolean value indicate whether the gradient is correct or not}
        
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{true\PYZus{}gradient} \PY{o}{=} \PY{n}{compute\PYZus{}square\PYZus{}loss\PYZus{}gradient}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{theta}\PY{p}{)} \PY{c}{\PYZsh{}the true gradient}
            \PY{n}{num\PYZus{}features} \PY{o}{=} \PY{n}{theta}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
            \PY{n}{approx\PYZus{}grad} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}features}\PY{p}{)} \PY{c}{\PYZsh{}Initialize the gradient we approximate}
            
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{num\PYZus{}features}\PY{p}{)}\PY{p}{:}
                \PY{n}{e} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}features}\PY{p}{)}
                \PY{n}{e}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{=}\PY{l+m+mi}{1}
            
                \PY{n}{approx\PYZus{}grad}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{p}{(}\PY{n}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta} \PY{o}{+} \PY{n}{epsilon} \PY{o}{*} \PY{n}{e}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta} \PY{o}{\PYZhy{}} \PY{n}{epsilon}\PY{o}{*}\PY{n}{e}\PY{p}{)}\PY{p}{)}\PY{o}{*}\PY{l+m+mf}{1.0} \PY{o}{/} \PY{p}{(}\PY{l+m+mf}{2.0}\PY{o}{*}\PY{n}{epsilon}\PY{p}{)}
            
            \PY{n}{dist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{true\PYZus{}gradient} \PY{o}{\PYZhy{}} \PY{n}{approx\PYZus{}grad}\PY{p}{)}
            \PY{n}{correct\PYZus{}grad} \PY{o}{=} \PY{n}{dist}\PY{o}{\PYZlt{}}\PY{n}{tolerance}
            \PY{k}{assert} \PY{n}{correct\PYZus{}grad}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gradient bad: dist }\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{ is greater than tolerance }\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{dist}\PY{p}{,}\PY{n}{tolerance}\PY{p}{)}
            \PY{k}{return} \PY{n}{correct\PYZus{}grad}
\end{Verbatim}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{2.4 Batch Gradient Descent}\label{batch-gradient-descent}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Complete \texttt{batch\_gradient\_descent} \textgreater{}See next cell
\item
  Starting with a step-size of 0.1 (not a bad one to start with), try
  various different fixed step sizes to see which converges most
  quickly. Plot the value of the objective function as a function of the
  number of steps. Briefly summarize your findings. \textgreater{}See
  next cell
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}Q2.4a: Batch Gradient Descent}
        \PY{k}{def} \PY{n+nf}{batch\PYZus{}grad\PYZus{}descent}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{check\PYZus{}grad}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    In this question you will implement batch gradient descent to}
        \PY{l+s+sd}{    minimize the square loss objective}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        X \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
        \PY{l+s+sd}{        y \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
        \PY{l+s+sd}{        alpha \PYZhy{} step size in gradient descent}
        \PY{l+s+sd}{        num\PYZus{}iter \PYZhy{} number of iterations to run }
        \PY{l+s+sd}{        check\PYZus{}grad \PYZhy{} a boolean value indicating whether checking the gradient when updating}
        \PY{l+s+sd}{        }
        \PY{l+s+sd}{    Returns:}
        \PY{l+s+sd}{        theta\PYZus{}hist \PYZhy{} store the the history of parameter vector in iteration, 2D numpy array of size (num\PYZus{}iter+1, num\PYZus{}features) }
        \PY{l+s+sd}{                    for instance, theta in iteration 0 should be theta\PYZus{}hist[0], theta in ieration (num\PYZus{}iter) is theta\PYZus{}hist[\PYZhy{}1]}
        \PY{l+s+sd}{        loss\PYZus{}hist \PYZhy{} the history of objective function vector, 1D numpy array of size (num\PYZus{}iter+1) }
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{p}{(}\PY{n}{num\PYZus{}instances}\PY{p}{,} \PY{n}{num\PYZus{}features}\PY{p}{)} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{shape}
            \PY{n}{theta\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}features}\PY{p}{)}\PY{p}{)}  \PY{c}{\PYZsh{}Initialize theta\PYZus{}hist}
            \PY{n}{loss\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)} \PY{c}{\PYZsh{}initialize loss\PYZus{}hist}
            \PY{n}{theta} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{n}{num\PYZus{}features}\PY{p}{)} \PY{c}{\PYZsh{}initialize theta}
                
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{p}{)}\PY{p}{:}
                \PY{n}{theta\PYZus{}hist}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{theta}
                \PY{n}{loss\PYZus{}hist}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
                \PY{k}{if} \PY{n}{check\PYZus{}grad}\PY{p}{:}
                    \PY{n}{grad\PYZus{}check} \PY{o}{=} \PY{n}{grad\PYZus{}checker}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
                    \PY{k}{print} \PY{l+s}{\PYZdq{}}\PY{l+s}{grad\PYZus{}check:}\PY{l+s}{\PYZdq{}}\PY{p}{,}\PY{n}{grad\PYZus{}check}
                \PY{n}{grad} \PY{o}{=} \PY{n}{compute\PYZus{}square\PYZus{}loss\PYZus{}gradient}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
                \PY{n}{theta} \PY{o}{=} \PY{n}{theta} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{o}{*}\PY{n}{grad}
               
            \PY{n}{theta\PYZus{}hist}\PY{p}{[}\PY{n}{num\PYZus{}iter}\PY{p}{]} \PY{o}{=} \PY{n}{theta}
            \PY{n}{loss\PYZus{}hist}\PY{p}{[}\PY{n}{num\PYZus{}iter}\PY{p}{]} \PY{o}{=} \PY{n}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
            \PY{k}{return} \PY{n}{loss\PYZus{}hist}\PY{p}{,}\PY{n}{theta\PYZus{}hist}
        
        \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}Q2.4b: Plot convergence at various step sizes}
        \PY{k}{def} \PY{n+nf}{plot\PYZus{}step\PYZus{}convergence}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{num\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Plots instances of batch\PYZus{}grad\PYZus{}descent at various step\PYZus{}sizes (alphas)}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{step\PYZus{}sizes} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.001}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.101}\PY{p}{]}
            \PY{k}{for} \PY{n}{step\PYZus{}size} \PY{o+ow}{in} \PY{n}{step\PYZus{}sizes}\PY{p}{:}
                \PY{n}{loss\PYZus{}hist}\PY{p}{,}\PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{batch\PYZus{}grad\PYZus{}descent}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{alpha}\PY{o}{=}\PY{n}{step\PYZus{}size}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{o}{=}\PY{n}{num\PYZus{}iter}\PY{p}{)}
                \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{loss\PYZus{}hist}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{n}{step\PYZus{}size}\PY{p}{)}
            
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Steps}\PY{l+s}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Loss}\PY{l+s}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{yscale}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{log}\PY{l+s}{\PYZsq{}}\PY{p}{)}    
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Convergence Rates by Step Size}\PY{l+s}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
            
        \PY{n}{plot\PYZus{}step\PYZus{}convergence}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ML HW 1_files/ML HW 1_9_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{\texorpdfstring{2.5 Ridge Regression (i.e.~Linear
Regression with \(L_2\)
regularization)}{2.5 Ridge Regression (i.e.~Linear Regression with L\_2 regularization)}}\label{ridge-regression-i.e.linear-regression-with-lux5f2-regularization}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Compute the gradient of \(J(\theta)\) and write down the expression
  for updating \(\theta\) in the gradient descent algorithm.
  \textgreater{}\(\nabla J(\theta) = \frac{1}{m}(X\theta - y)^TX + 2\lambda \theta ^T\)
\item
  Implement \texttt{compute\ regularized\ square\ loss\ gradient}.
  \textgreater{} See next cell.
\item
  Implement \texttt{regularized\ grad\ descent}. \textgreater{} See next
  cell.
\item
  Explain why making \(B\) large decreases the effective regularization
  on the bias term, and how we can make that regularization as weak as
  we like (though not zero). \textgreater{} The bias term represents
  \(\hat{y} = B*\theta_B\) when \(X=0\). So a larger \(B\) means smaller
  \(\theta_B\), before regularization; and a smaller penalty for weight
  in the bias term.
\item
  Start with \(B = 1\). Choosing a reasonable step-size, find the
  \(\theta _\lambda^∗\) that minimizes \(J(\theta)\) for a range of λ
  and plot both the training loss and the validation loss as a function
  of λ. (Note that this is just the square loss, not including the
  regularization term.) You should initially try λ over several orders
  of magnitude to find an appropriate range (e.g .
  \(λ ∈ 􏰀\{10^{−2}, 10^{−1}, 1, 10,100\}\)􏰁. You may want to have
  \(log(λ)\) on the \(x\)-axis rather than λ. Once you have found the
  interesting range for λ, repeat the fits with different values for
  \(B\), and plot the results on the same graph. For this dataset, does
  regularizing the bias help, hurt, or make no significant difference?
  \textgreater{}See next cell
\item
  Estimate the average time it takes on your computer to compute a
  single gradient step. \textgreater{}I ran a test on the regularized
  gradient descent function, and it took approximately 69 microsends to
  run 1000 steps, which translates to 69 nanoseconds per step. See code
  below
\item
  What \(\theta\) would you select for deployment and why?
  \textgreater{} I believe this question is asking for \(\lambda\). I
  found the minimum square loss to be 1.4, at \(\lambda = 0.01\)
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}94}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}Q2.5a: Compute the gradient of Regularized Batch Gradient Descent}
         \PY{k}{def} \PY{n+nf}{compute\PYZus{}regularized\PYZus{}square\PYZus{}loss\PYZus{}gradient}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{theta}\PY{p}{,} \PY{n}{lambda\PYZus{}reg}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Compute the gradient of L2\PYZhy{}regularized square loss function given X, y and theta}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Args:}
         \PY{l+s+sd}{        X \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
         \PY{l+s+sd}{        y \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
         \PY{l+s+sd}{        theta \PYZhy{} the parameter vector, 1D numpy array of size (num\PYZus{}features)}
         \PY{l+s+sd}{        lambda\PYZus{}reg \PYZhy{} the regularization coefficient}
         \PY{l+s+sd}{    }
         \PY{l+s+sd}{    Returns:}
         \PY{l+s+sd}{        grad \PYZhy{} gradient vector, 1D numpy array of size (num\PYZus{}features)}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{m}\PY{o}{=}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
             \PY{n}{yhat} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
             \PY{n}{grad} \PY{o}{=} \PY{l+m+mf}{1.0}\PY{o}{/}\PY{n}{m} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{p}{(}\PY{n}{yhat} \PY{o}{\PYZhy{}} \PY{n}{y}\PY{p}{)}\PY{p}{,}\PY{n}{X}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{2.0}\PY{o}{*}\PY{n}{lambda\PYZus{}reg}\PY{o}{*}\PY{n}{theta}
             \PY{k}{return} \PY{n}{grad}
         
         
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}Q2.5b: Batch Gradient Descent with regularization term}
         \PY{k}{def} \PY{n+nf}{regularized\PYZus{}grad\PYZus{}descent}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{lambda\PYZus{}reg}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Args:}
         \PY{l+s+sd}{        X \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
         \PY{l+s+sd}{        y \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
         \PY{l+s+sd}{        alpha \PYZhy{} step size in gradient descent}
         \PY{l+s+sd}{        lambda\PYZus{}reg \PYZhy{} the regularization coefficient}
         \PY{l+s+sd}{        numIter \PYZhy{} number of iterations to run }
         \PY{l+s+sd}{        }
         \PY{l+s+sd}{    Returns:}
         \PY{l+s+sd}{        theta\PYZus{}hist \PYZhy{} the history of parameter vector, 2D numpy array of size (num\PYZus{}iter+1, num\PYZus{}features) }
         \PY{l+s+sd}{        loss\PYZus{}hist \PYZhy{} the history of regularized loss value, 1D numpy array}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{p}{(}\PY{n}{num\PYZus{}instances}\PY{p}{,} \PY{n}{num\PYZus{}features}\PY{p}{)} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{shape}
             \PY{n}{theta} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{n}{num\PYZus{}features}\PY{p}{)} \PY{c}{\PYZsh{}Initialize theta}
             \PY{n}{theta\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}features}\PY{p}{)}\PY{p}{)}  \PY{c}{\PYZsh{}Initialize theta\PYZus{}hist}
             \PY{n}{loss\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)} \PY{c}{\PYZsh{}Initialize loss\PYZus{}hist}
                 
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
                 \PY{n}{theta\PYZus{}hist}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{theta}
                 \PY{n}{loss\PYZus{}hist}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta}\PY{p}{,}\PY{n}{lambda\PYZus{}reg}\PY{o}{=}\PY{n}{lambda\PYZus{}reg}\PY{p}{)}
                 \PY{n}{grad} \PY{o}{=} \PY{n}{compute\PYZus{}regularized\PYZus{}square\PYZus{}loss\PYZus{}gradient}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta}\PY{p}{,}\PY{n}{lambda\PYZus{}reg}\PY{p}{)}
                 \PY{c}{\PYZsh{}Make gradient a unit vector}
                 \PY{n}{theta} \PY{o}{=} \PY{n}{theta} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{o}{*}\PY{n}{grad}\PY{o}{/}\PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{grad}\PY{p}{)}
             
             \PY{k}{assert} \PY{n}{loss\PYZus{}hist}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{\PYZgt{}}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Loss history[0] is still zero}\PY{l+s}{\PYZdq{}}
             \PY{k}{assert} \PY{n}{theta\PYZus{}hist}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{\PYZgt{}}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Theta\PYZus{}hist[0] is is still zero}\PY{l+s}{\PYZdq{}}
             \PY{k}{return} \PY{n}{loss\PYZus{}hist}\PY{p}{,}\PY{n}{theta\PYZus{}hist}
             
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{c}{\PYZsh{}\PYZsh{}Q2.5c: Visualization of Regularized Batch Gradient Descent}
         
         \PY{k}{def} \PY{n+nf}{plot\PYZus{}regularized\PYZus{}grad}\PY{p}{(}\PY{n}{X\PYZus{}tr}\PY{p}{,}\PY{n}{y\PYZus{}tr}\PY{p}{,}\PY{n}{X\PYZus{}val}\PY{p}{,}\PY{n}{y\PYZus{}val}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Args:}
         \PY{l+s+sd}{        X\PYZus{}tr \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
         \PY{l+s+sd}{        y\PYZus{}tr \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
         \PY{l+s+sd}{        X\PYZus{}val \PYZhy{} the feature vector from test data}
         \PY{l+s+sd}{        y\PYZus{}val \PYZhy{} the label vector from test data}
         \PY{l+s+sd}{        alpha \PYZhy{} step size in gradient descent}
         \PY{l+s+sd}{        numIter \PYZhy{} number of iterations to run }
         \PY{l+s+sd}{        }
         \PY{l+s+sd}{    Returns:}
         \PY{l+s+sd}{        Plot}
         \PY{l+s+sd}{        X\PYZhy{}axis: log(lambda\PYZus{}reg)}
         \PY{l+s+sd}{        Y\PYZhy{}axis: square\PYZus{}loss (training and test)  }
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{biases} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{]}
             \PY{n}{colors} \PY{o}{=} \PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{c}\PY{l+s}{\PYZsq{}}\PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{g}\PY{l+s}{\PYZsq{}}\PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{y}\PY{l+s}{\PYZsq{}}\PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{r}\PY{l+s}{\PYZsq{}}\PY{p}{]}
             \PY{n}{lambda\PYZus{}exponents} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{n}{lambda\PYZus{}regs} \PY{o}{=} \PY{n+nb}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{l+m+mi}{10}\PY{o}{*}\PY{o}{*}\PY{n}{x}\PY{p}{,} \PY{n}{lambda\PYZus{}exponents}\PY{p}{)}
             
             \PY{c}{\PYZsh{}initialize square loss}
             \PY{n}{training\PYZus{}loss} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{lambda\PYZus{}regs}\PY{p}{)}\PY{p}{)}
             \PY{n}{test\PYZus{}loss} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{lambda\PYZus{}regs}\PY{p}{)}\PY{p}{)}    
             
             \PY{c}{\PYZsh{}initialize plot}
             \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{p}{)}
             \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{111}\PY{p}{)}
             
             \PY{n}{first\PYZus{}run}\PY{o}{=}\PY{n+nb+bp}{True}
             \PY{k}{for} \PY{n}{j}\PY{p}{,}\PY{n}{bias} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{biases}\PY{p}{)}\PY{p}{:}
                 \PY{c}{\PYZsh{}adjust bias term}
                 \PY{n}{X\PYZus{}tr}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{bias}
                 
                 \PY{k}{for} \PY{n}{i}\PY{p}{,}\PY{n}{lambda\PYZus{}reg} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{lambda\PYZus{}regs}\PY{p}{)}\PY{p}{:}
                     \PY{n}{loss\PYZus{}hist}\PY{p}{,}\PY{n}{theta\PYZus{}hist} \PY{o}{=} \PY{n}{regularized\PYZus{}grad\PYZus{}descent}\PY{p}{(}\PY{n}{X\PYZus{}tr}\PY{p}{,}\PY{n}{y\PYZus{}tr}\PY{p}{,} \PY{n}{alpha}\PY{p}{,}\PY{n}{lambda\PYZus{}reg}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{p}{)}
                     \PY{n}{training\PYZus{}loss}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{loss\PYZus{}hist}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
                     \PY{n}{test\PYZus{}loss}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{,}\PY{n}{y\PYZus{}val}\PY{p}{,}\PY{n}{theta\PYZus{}hist}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
                     
                     \PY{c}{\PYZsh{}Record new low\PYZhy{}loss mark}
                     \PY{k}{if} \PY{n}{first\PYZus{}run} \PY{o+ow}{or} \PY{n}{test\PYZus{}loss}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{n}{min\PYZus{}test\PYZus{}loss}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{:}
                         \PY{n}{min\PYZus{}test\PYZus{}loss}\PY{o}{=}\PY{p}{[}\PY{n}{test\PYZus{}loss}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,}\PY{n}{bias}\PY{p}{,}\PY{n}{lambda\PYZus{}reg}\PY{p}{]}
                     \PY{n}{first\PYZus{}run}\PY{o}{=}\PY{n+nb+bp}{False}                
                 
                 \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{lambda\PYZus{}regs}\PY{p}{,}\PY{n}{training\PYZus{}loss}\PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{\PYZhy{}\PYZhy{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{colors}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{training B=}\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{bias}\PY{p}{)}
                 \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{lambda\PYZus{}regs}\PY{p}{,}\PY{n}{test\PYZus{}loss}\PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{\PYZhy{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{colors}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{validation B=}\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{bias}\PY{p}{)}
                     
             \PY{c}{\PYZsh{} Shrink current axis by 20\PYZpc{}}
             \PY{n}{box} \PY{o}{=} \PY{n}{ax}\PY{o}{.}\PY{n}{get\PYZus{}position}\PY{p}{(}\PY{p}{)}
             \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}position}\PY{p}{(}\PY{p}{[}\PY{n}{box}\PY{o}{.}\PY{n}{x0}\PY{p}{,} \PY{n}{box}\PY{o}{.}\PY{n}{y0}\PY{p}{,} \PY{n}{box}\PY{o}{.}\PY{n}{width} \PY{o}{*} \PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{box}\PY{o}{.}\PY{n}{height}\PY{p}{]}\PY{p}{)}
             \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{center left}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{bbox\PYZus{}to\PYZus{}anchor}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
             \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Loss, Varying Bias Term }\PY{l+s}{\PYZdq{}}\PY{l+s}{B}\PY{l+s}{\PYZdq{}}\PY{l+s}{ and Lambda}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xscale}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{log}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Regularization term Lambda}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Square Loss}\PY{l+s}{\PYZsq{}}\PY{p}{)} 
             \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
             \PY{k}{print} \PY{l+s}{\PYZdq{}}\PY{l+s}{Minimum loss is }\PY{l+s+si}{\PYZpc{}f}\PY{l+s}{, found at Bias=}\PY{l+s+si}{\PYZpc{}d}\PY{l+s}{ and Lambda=}\PY{l+s+si}{\PYZpc{}f}\PY{l+s}{\PYZdq{}} \PY{o}{\PYZpc{}}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{min\PYZus{}test\PYZus{}loss}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{min\PYZus{}test\PYZus{}loss}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{n}{min\PYZus{}test\PYZus{}loss}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}95}]:} \PY{n}{plot\PYZus{}regularized\PYZus{}grad}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{n}{X\PYZus{}test}\PY{p}{,}\PY{n}{y\PYZus{}test}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ML HW 1_files/ML HW 1_12_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Minimum loss is 1.200000, found at Bias=1 and Lambda=0.010000
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}87}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{c}{\PYZsh{}\PYZsh{}Q2.5.6: Estimate the average time it takes on your computer }
         \PY{c}{\PYZsh{}\PYZsh{}to compute a single gradient step.}
         
         \PY{k}{def} \PY{n+nf}{timeme}\PY{p}{(}\PY{n}{func}\PY{p}{,}\PY{o}{*}\PY{n}{args}\PY{p}{,}\PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Timer wrapper.  Runs a given function, with arguments,}
         \PY{l+s+sd}{    100 times and displays the average time per run.  }
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{k}{def} \PY{n+nf}{wrapper}\PY{p}{(}\PY{n}{func}\PY{p}{,} \PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
                 \PY{k}{def} \PY{n+nf}{wrapped}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                     \PY{k}{return} \PY{n}{func}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}
                 \PY{k}{return} \PY{n}{wrapped}
             \PY{n}{wrapped} \PY{o}{=} \PY{n}{wrapper}\PY{p}{(}\PY{n}{func}\PY{p}{,}\PY{o}{*}\PY{n}{args}\PY{p}{,}\PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}
             \PY{n}{run\PYZus{}time} \PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{n}{timeit}\PY{o}{.}\PY{n}{timeit}\PY{p}{(}\PY{n}{wrapped}\PY{p}{,} \PY{n}{number}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{10}
             \PY{k}{print} \PY{l+s}{\PYZdq{}}\PY{l+s}{Avg time to run }\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{ after 100 trials: }\PY{l+s+si}{\PYZpc{}i}\PY{l+s}{ µs per trial}\PY{l+s}{\PYZdq{}} \PY{o}{\PYZpc{}}\PY{p}{(}\PY{n}{func}\PY{p}{,}\PY{n}{run\PYZus{}time}\PY{p}{)}
             
         \PY{n}{timeme}\PY{p}{(}\PY{n}{regularized\PYZus{}grad\PYZus{}descent}\PY{p}{,}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Avg time to run <function regularized\_grad\_descent at 0x108e3b8c0> after 100 trials: 89 µs per trial
    \end{Verbatim}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsubsection{2.6 Stochastic Gradient
Descent}\label{stochastic-gradient-descent}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write down the update rule for \(\theta\) in SGD.
  \textgreater{}Stochastic gradient at point \(i\) is given by
  \[\nabla J_i(\theta) = (\vec{x_i}^T\theta - y_i)\vec{x_i} + 2\lambda \theta^T\]
  where \(\vec{x_i}\) is the feature vector for instance \(i\) and
  \(y_i\) is a scalar
\item
  Implement stochastic\_grad\_descent \textgreater{} See next cell
\item
  Use SGD to find \(θλ^∗\) that minimizes the ridge regression objective
  for the \(λ\) and \(B\) that you selected in the previous problem. Try
  several different fixed step sizes, as well as step sizes that
  decrease with the step number according to the following schedules:
  \(η = \frac{1}{t}\) and \(η = \frac{1}{\sqrt{t}}\) Plot the value of
  the objective function (or the log of the objective function if that
  is more clear) as a function of epoch (or step number) for each of the
  approaches to step size. How do the results compare? (Note: In this
  case we are investigating the convergence rate of the optimization
  algorithm, thus we're interested in the value of the objective
  function, which includes the regularization term.) \textgreater{} See
  next cell
\item
  Estimate the amount of time it takes on your computer for a single
  epoch of SGD. \textgreater{} The test below showed that 100 epochs
  takes 550µs, or 5.5µs per epoch.
\item
  Comparing SGD and gradient descent, if your goal is to minimize the
  total number of epochs (for SGD) or steps (for batch gradient
  descent), which would you choose? If your goal were to minimize the
  total time, which would you choose? \textgreater{} Gradient descent
  converges in 1000 steps; 69 nanoseconds per step, that's 69µs. SGD
  converges in fewer than 10 epochs; at 5.5µs per epoch, that's less
  than 50µs. SGD is fewer steps and less time.
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}113}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
          \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}Q2.6a: Stochastic Gradient Descent    }
          \PY{k}{def} \PY{n+nf}{compute\PYZus{}stochastic\PYZus{}gradient}\PY{p}{(}\PY{n}{X\PYZus{}i}\PY{p}{,}\PY{n}{y\PYZus{}i}\PY{p}{,}\PY{n}{theta}\PY{p}{,} \PY{n}{lambda\PYZus{}reg}\PY{p}{)}\PY{p}{:}
              \PY{n}{yhat} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{X\PYZus{}i}\PY{p}{,}\PY{n}{theta}\PY{p}{)}
              \PY{n}{grad} \PY{o}{=} \PY{p}{(}\PY{n}{yhat} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}i}\PY{p}{)}\PY{o}{*}\PY{n}{X\PYZus{}i} \PY{o}{+} \PY{l+m+mf}{2.0}\PY{o}{*}\PY{n}{lambda\PYZus{}reg}\PY{o}{*}\PY{n}{theta}
              \PY{k}{return} \PY{n}{grad}
          
          \PY{k}{def} \PY{n+nf}{stochastic\PYZus{}grad\PYZus{}descent}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{lambda\PYZus{}reg}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    In this question you will implement stochastic gradient descent with a regularization term}
          \PY{l+s+sd}{    }
          \PY{l+s+sd}{    Args:}
          \PY{l+s+sd}{        X \PYZhy{} the feature vector, 2D numpy array of size (num\PYZus{}instances, num\PYZus{}features)}
          \PY{l+s+sd}{        y \PYZhy{} the label vector, 1D numpy array of size (num\PYZus{}instances)}
          \PY{l+s+sd}{        alpha \PYZhy{} string or float. step size in gradient descent}
          \PY{l+s+sd}{                NOTE: In SGD, it\PYZsq{}s not always a good idea to use a fixed step size. Usually it\PYZsq{}s set to 1/sqrt(t) or 1/t}
          \PY{l+s+sd}{                if alpha is a float, then the step size in every iteration is alpha.}
          \PY{l+s+sd}{                if alpha == \PYZdq{}1/sqrt(t)\PYZdq{}, alpha = 1/sqrt(t)}
          \PY{l+s+sd}{                if alpha == \PYZdq{}1/t\PYZdq{}, alpha = 1/t}
          \PY{l+s+sd}{        lambda\PYZus{}reg \PYZhy{} the regularization coefficient}
          \PY{l+s+sd}{        num\PYZus{}iter \PYZhy{} number of epochs (i.e number of times) to go through the whole training set}
          \PY{l+s+sd}{    }
          \PY{l+s+sd}{    Returns:}
          \PY{l+s+sd}{        theta\PYZus{}hist \PYZhy{} the history of parameter vector, 3D numpy array of size (num\PYZus{}iter, num\PYZus{}instances, num\PYZus{}features) }
          \PY{l+s+sd}{        loss hist \PYZhy{} the history of regularized loss function vector, 2D numpy array of size(num\PYZus{}iter, num\PYZus{}instances)}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{num\PYZus{}instances}\PY{p}{,} \PY{n}{num\PYZus{}features} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{shape}
              \PY{n}{theta} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{n}{num\PYZus{}features}\PY{p}{)} \PY{c}{\PYZsh{}Initialize theta}
              
              \PY{n}{theta\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{p}{,} \PY{n}{num\PYZus{}instances}\PY{p}{,} \PY{n}{num\PYZus{}features}\PY{p}{)}\PY{p}{)}  \PY{c}{\PYZsh{}Initialize theta\PYZus{}hist}
              \PY{n}{loss\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{p}{,} \PY{n}{num\PYZus{}instances}\PY{p}{)}\PY{p}{)} \PY{c}{\PYZsh{}Initialize loss\PYZus{}hist}
              \PY{n}{step\PYZus{}size} \PY{o}{=} \PY{l+m+mf}{0.01}
              \PY{n}{t}\PY{o}{=}\PY{l+m+mi}{1}
              \PY{n}{index\PYZus{}order} \PY{o}{=} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}instances}\PY{p}{)}
              
              \PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{p}{)}\PY{p}{:}
                  \PY{c}{\PYZsh{}maybe random shuffle here}
                  \PY{c}{\PYZsh{}np.random.shuffle(index\PYZus{}order)}
                  \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{rand\PYZus{}idx} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{index\PYZus{}order}\PY{p}{)}\PY{p}{:}            
                      \PY{c}{\PYZsh{}options for alpha are float, 1/t, or 1/sqrt(t)}
                      \PY{k}{if} \PY{n}{alpha}\PY{o}{==}\PY{l+s}{\PYZdq{}}\PY{l+s}{1/t}\PY{l+s}{\PYZdq{}}\PY{p}{:}
                          \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n}{t}\PY{p}{)}
                      \PY{k}{elif} \PY{n}{alpha}\PY{o}{==}\PY{l+s}{\PYZdq{}}\PY{l+s}{1/sqrt(t)}\PY{l+s}{\PYZdq{}}\PY{p}{:}
                          \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{o}{/}\PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{t}\PY{p}{)}
                      \PY{k}{else}\PY{p}{:}
                          \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{n}{alpha}
                      
                      \PY{n}{theta\PYZus{}hist}\PY{p}{[}\PY{n}{epoch}\PY{p}{,}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{theta}
                      \PY{n}{loss\PYZus{}hist}\PY{p}{[}\PY{n}{epoch}\PY{p}{,}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{compute\PYZus{}square\PYZus{}loss}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{theta}\PY{p}{,}\PY{n}{lambda\PYZus{}reg}\PY{p}{)}
                      \PY{n}{grad} \PY{o}{=} \PY{n}{compute\PYZus{}stochastic\PYZus{}gradient}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{n}{rand\PYZus{}idx}\PY{p}{,}\PY{p}{:}\PY{p}{]}\PY{p}{,}\PY{n}{y}\PY{p}{[}\PY{n}{rand\PYZus{}idx}\PY{p}{]}\PY{p}{,}\PY{n}{theta}\PY{p}{,}\PY{n}{lambda\PYZus{}reg}\PY{p}{)}
                      \PY{n}{theta} \PY{o}{=} \PY{n}{theta} \PY{o}{\PYZhy{}} \PY{n}{step\PYZus{}size}\PY{o}{*}\PY{n}{grad}
                      \PY{n}{t}\PY{o}{=}\PY{n}{t}\PY{o}{+}\PY{l+m+mi}{1}
          
              \PY{k}{return} \PY{n}{loss\PYZus{}hist}\PY{p}{,}\PY{n}{theta\PYZus{}hist}
              
          
          \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
          \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}Q2.6b Visualization that compares the convergence speed of batch}
          \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}and stochastic gradient descent for various approaches to step\PYZus{}size}
          \PY{c}{\PYZsh{}\PYZsh{}X\PYZhy{}axis: Step number (for gradient descent) or Epoch (for SGD)}
          \PY{c}{\PYZsh{}\PYZsh{}Y\PYZhy{}axis: log(objective\PYZus{}function\PYZus{}value)}
          \PY{k}{def} \PY{n+nf}{plot\PYZus{}stochastic}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{lambda\PYZus{}reg}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{:}
              \PY{n}{num\PYZus{}instances}\PY{p}{,} \PY{n}{num\PYZus{}features} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{shape}
              \PY{n}{alphas} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.01}\PY{p}{,}\PY{l+m+mf}{0.05}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{1/t}\PY{l+s}{\PYZdq{}}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{1/sqrt(t)}\PY{l+s}{\PYZdq{}}\PY{p}{]}
          
              \PY{c}{\PYZsh{}initialize plot}
              \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{p}{)}
              \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{111}\PY{p}{)}
                 
              
              \PY{k}{for} \PY{n}{i}\PY{p}{,}\PY{n}{alpha} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{alphas}\PY{p}{)}\PY{p}{:}        
                  \PY{n}{loss\PYZus{}hist}\PY{p}{,}\PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{stochastic\PYZus{}grad\PYZus{}descent}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{alpha}\PY{p}{,}\PY{n}{lambda\PYZus{}reg}\PY{p}{,} \PY{n}{num\PYZus{}iter}\PY{p}{)}
                  \PY{c}{\PYZsh{}plot the last instance from each iteration}
                  \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}iter}\PY{p}{)}\PY{p}{,}\PY{n}{loss\PYZus{}hist}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{alpha=}\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{alpha}\PY{p}{)}
              
              \PY{c}{\PYZsh{} Shrink current axis by 20\PYZpc{}}
              \PY{n}{box} \PY{o}{=} \PY{n}{ax}\PY{o}{.}\PY{n}{get\PYZus{}position}\PY{p}{(}\PY{p}{)}
              \PY{c}{\PYZsh{}Position legend}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}position}\PY{p}{(}\PY{p}{[}\PY{n}{box}\PY{o}{.}\PY{n}{x0}\PY{p}{,} \PY{n}{box}\PY{o}{.}\PY{n}{y0}\PY{p}{,} \PY{n}{box}\PY{o}{.}\PY{n}{width} \PY{o}{*} \PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{box}\PY{o}{.}\PY{n}{height}\PY{p}{]}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{center left}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{bbox\PYZus{}to\PYZus{}anchor}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
              
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Rates of convergence for various Alphas}\PY{l+s}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}yscale}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{log}\PY{l+s}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Epochs}\PY{l+s}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Square Loss}\PY{l+s}{\PYZsq{}}\PY{p}{)} 
              \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}114}]:} \PY{n}{plot\PYZus{}stochastic}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ML HW 1_files/ML HW 1_16_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}106}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
          \PY{c}{\PYZsh{}\PYZsh{}Q2.6.4}
          \PY{n}{timeme}\PY{p}{(}\PY{n}{stochastic\PYZus{}grad\PYZus{}descent}\PY{p}{,}\PY{n}{X\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Avg time to run <function stochastic\_grad\_descent at 0x109636578> after 100 trials: 550 µs per trial
    \end{Verbatim}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{3 Risk Minimization}\label{risk-minimization}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Show that for the square loss
  \(\ell(\hat{y}, y) = \frac{1}{2}(y − \hat{y})^2\), the Bayes decision
  function is a \(f_∗(x) = \mathbb{E} [Y | X = x]\). {[}Hint: Consider
  constructing \(f_∗ (x)\), one \(x\) at a time.{]} \textgreater{}See
  image below:
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{files/image.png}\PY{l+s}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}4}]:}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{ML HW 1_files/ML HW 1_19_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}}]:} 
\end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
