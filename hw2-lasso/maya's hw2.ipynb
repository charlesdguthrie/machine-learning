{
 "metadata": {
  "name": "",
  "signature": "sha256:0b8dd791c6c4360713bf93472423e379a276bac5eb2a22c86cd3374b9118c9d4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.optimize import minimize\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "import time \n",
      "%matplotlib inline\n",
      "\n",
      "def make_dataset(seed = 1):\n",
      "    '''\n",
      "    Args:\n",
      "        seed = adjust seed for easy replication\n",
      "\n",
      "    Returns:\n",
      "        data = the feature vector, 2D numpy array of size (m, d)\n",
      "     '''\n",
      "\n",
      "    m = 150 # exaples\n",
      "    d = 75 # features\n",
      "\n",
      "    np.random.seed(seed)  # for easy replication\n",
      "    data = np.random.rand(m,d)\n",
      "\n",
      "    assert data.shape == (150,75)\n",
      "\n",
      "    return data\n",
      "\n",
      "def construct_true_theta(seed = 1):\n",
      "    '''\n",
      "    Args:\n",
      "        seed = adjust seed for easy replication\n",
      "\n",
      "    Returns:\n",
      "        theta = a (d,) vector. first 10 entries are arbitrarily set to 10 or -10. the remainder of the entries are 0.\n",
      "    \n",
      "     '''\n",
      "    \n",
      "    d = 75 #features\n",
      "    half_theta = np.zeros(65)\n",
      "\n",
      "    # Set the first 10 components of theta to 10 or -10 arbitrarily\n",
      "    np.random.seed(seed) # for easy replication\n",
      "    first_ten = np.random.randint(2, size=10)\n",
      "    first_ten[first_ten==0] = -10\n",
      "    first_ten[first_ten==1] = 10\n",
      "\n",
      "    theta = np.concatenate((first_ten, half_theta), axis=0)\n",
      "\n",
      "    return theta \n",
      "\n",
      "\n",
      "def construct_target(X, theta, seed = 1):\n",
      "    '''\n",
      "    Args:\n",
      "        seed = adjust seed for easy replication\n",
      "        X = the feature vector, 2D numpy array of size (m, d)\n",
      "        theta = the true theta that we will later attempt to find. (d,)\n",
      "\n",
      "    Returns:\n",
      "        y_noisy = the constructed target variable with added noise. 1D numpy array of size (m,)\n",
      "    \n",
      "     '''\n",
      "    \n",
      "    m = 150 # rows\n",
      "   \n",
      "    # find true y\n",
      "    y_true = X.dot(theta)\n",
      "\n",
      "    # add noise, with mean 0 and standard deviation 0.1.\n",
      "    sigma = 0.1\n",
      "    np.random.seed(seed)  # for easy replication\n",
      "    noise = sigma * np.random.randn(m)\n",
      "\n",
      "    y_noisy  = y_true + noise \n",
      "    return y_noisy\n",
      "\n",
      "\n",
      "def train_test_split(X,y):\n",
      "    ''' The function splits the dataset by taking the first 80 points for training, \n",
      "    the next 20 points for validation, and the last 50 points for testing.\n",
      "    Args:\n",
      "        X = the feature vector, 2D numpy array of size (m, d)\n",
      "        y = the label vector, 1D numpy array of size (m,)\n",
      "    Returns:\n",
      "        X_train, y_train, X_validation, y_validation, X_test, y_test\n",
      "    '''\n",
      "\n",
      "    X_train, y_train = X[0:80],y[0:80]\n",
      "    X_validation, y_validation = X[80:100],y[80:100]\n",
      "    X_test, y_test = X[100:],y[100:]\n",
      "\n",
      "    return X_train, y_train, X_validation, y_validation, X_test, y_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = make_dataset()\n",
      "theta = construct_true_theta()\n",
      "y = construct_target(X,theta)\n",
      "(X_train, y_train, X_validation, y_validation, X_test, y_test)=train_test_split(X,y)\n",
      "X_train,y_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(array([[  4.17022005e-01,   7.20324493e-01,   1.14374817e-04, ...,\n",
        "           1.39276347e-01,   8.07391289e-01,   3.97676837e-01],\n",
        "        [  1.65354197e-01,   9.27508580e-01,   3.47765860e-01, ...,\n",
        "           7.12988980e-01,   5.59716982e-01,   1.25559802e-02],\n",
        "        [  7.19742797e-02,   9.67276330e-01,   5.68100462e-01, ...,\n",
        "           1.30996845e-01,   8.09490692e-01,   3.44736653e-01],\n",
        "        ..., \n",
        "        [  3.18453337e-02,   8.69477233e-03,   3.58537645e-01, ...,\n",
        "           4.37938936e-01,   2.66820995e-01,   9.54689225e-01],\n",
        "        [  9.36872134e-01,   4.34348752e-01,   4.31010688e-01, ...,\n",
        "           6.30109849e-01,   1.02572697e-01,   7.18643621e-01],\n",
        "        [  4.79683338e-01,   3.78993837e-01,   4.51846707e-01, ...,\n",
        "           2.61910196e-02,   9.50827989e-01,   5.69917642e-01]]),\n",
        " array([ 14.80009169,  30.51056418,  21.5870639 ,  22.93513867,\n",
        "         19.15872253,  19.80297624,  17.61321333,  20.3607927 ,\n",
        "         30.25121408,  35.41267863,  11.45541927,  17.91757715,\n",
        "         26.30820441,  14.60016773,  30.00907669,  14.56735891,\n",
        "         12.45530193,  18.38423232,  16.60301241,  29.73566509,\n",
        "         13.57976477,  14.76089186,  20.38171327,  18.93637128,\n",
        "         19.89847653,  27.74253704,   8.93071039,  24.73613777,\n",
        "         20.70842345,  23.42079959,  18.95935547,  18.31523317,\n",
        "         31.86159332,  11.92244979,  23.56046192,  15.30232569,\n",
        "         40.96881959,   9.33139959,  36.17579387,  28.54681553,\n",
        "         23.76520006,  22.7084099 ,  23.75011633,   6.35495632,\n",
        "          1.40760902,  10.55760045,  21.4856812 ,  24.3575252 ,\n",
        "          7.06734752,  19.46166625,   8.07276234,  25.91060272,\n",
        "         21.62106122,  26.25954363,  -3.27461714,  17.62982087,\n",
        "         13.53551194,  17.11476971,  29.75826272,  -2.35489548,\n",
        "         24.47264371,  22.60560352,  27.62135382,  16.47273018,\n",
        "         33.60887242,  27.15470967,  29.15446615,  24.80739004,\n",
        "         41.09230003,  32.03995414,  17.29099623,  32.76035081,\n",
        "         19.0648571 ,  28.68414038,  15.68757653,  20.39523094,\n",
        "         17.84952276,  19.4099924 ,  25.42786937,  23.88002655]))"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ridge(Lambda,X,y):\n",
      "    def ridge_obj(theta,X=X,y=y):\n",
      "        m=X.shape[0]\n",
      "        return ((np.linalg.norm(np.dot(X,theta) - y))**2)/(2*m) + Lambda*(np.linalg.norm(theta))**2\n",
      "    return ridge_obj\n",
      "\n",
      "\n",
      "def compute_loss(X, y, theta):\n",
      "    m = X.shape[0]\n",
      "    return ((np.linalg.norm(np.dot(X,theta) - y))**2)/(2*m)\n",
      "\n",
      "def find_optimal_lambda(X_train, y_train, X_validation, y_validation, theta):\n",
      "    ''' function to find the optimal lambda for ridge regression'''\n",
      "    min_cost = 1000.0\n",
      "    min_theta  = np.zeros(d)\n",
      "    min_Lambda = 0.0\n",
      "    # Choose the lambda that minimizes the square loss on the validation set.\n",
      "    for i in range(-9,4):\n",
      "        Lambda = 10**i;\n",
      "        w_opt = minimize(ridge(Lambda,X_train, y_train), theta, method= \"BFGS\")\n",
      "        new_cost = compute_loss(X_validation, y_validation, w_opt.x)\n",
      "        if new_cost<min_cost:\n",
      "            min_cost = new_cost\n",
      "            min_theta  = w_opt.x\n",
      "            min_Lambda = Lambda\n",
      "\n",
      "        print Lambda, new_cost, w_opt.success\n",
      "\n",
      "\n",
      "        #cost[Lambda] = compute_loss(X_validation, y_validation, w_opt.x)\n",
      "    print \"cost\", min_Lambda\n",
      "    return min_cost, min_theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shooting_algorithm(initial_theta, X, y, Lambda):\n",
      "    ''' \n",
      "    Args: \n",
      "        ridge_theta: The initial \"optimal\" theta we get from ridge regression\n",
      "        X = the feature vector, 2D numpy array of size (m, d)\n",
      "            i - row\n",
      "            j- feature\n",
      "        y = the label vector, 1D numpy array of size (m,)\n",
      "        Lambda = regularization factor\n",
      "    Returns:\n",
      "        theta_shooting = the optimal theta!\n",
      "\n",
      "    '''\n",
      "    theta_shooting = initial_theta.copy() \n",
      "    threshold = 0.000001\n",
      "\n",
      "    \n",
      "    #initialize loss values to ensure that while loop if entered\n",
      "    old_loss = 100000.0\n",
      "    new_loss = 0.0\n",
      "    \n",
      "    iter_counter = 0.0\n",
      "    \n",
      "    while (np.abs(old_loss - new_loss) >= threshold) and  iter_counter <5000:\n",
      "    #while np.linalg.norm(old_theta - theta_shooting) >= threshold:\n",
      "\n",
      "        iter_counter+=1\n",
      "        for feature in range(d):\n",
      "            # grab feature in question\n",
      "            X_j = X[:,feature]\n",
      "            a_j = 2*np.sum(X_j**2)\n",
      "            c_j = 0.0\n",
      "\n",
      "            for i in range(X.shape[0]):\n",
      "                c_j = c_j + 2*(X_j[i])*(y[i] - np.dot(theta_shooting, X[i])+theta_shooting[feature]*X_j[i])\n",
      "            \n",
      "            theta_shooting[feature] = soft_thresholding(a = (c_j/a_j) ,delta = (Lambda/a_j))\n",
      "        \n",
      "        new_loss = compute_loss(X, y, theta_shooting) + Lambda*np.linalg.norm(theta_shooting)\n",
      "\n",
      "\n",
      "        old_loss , new_loss = new_loss, old_loss\n",
      "\n",
      "    print \"final loss: \", new_loss, \" iterations : \", iter_counter\n",
      "    return theta_shooting\n",
      "\n",
      "def soft_thresholding(a,delta):\n",
      "    sign = math.copysign(1, a)\n",
      "    diff = (np.abs(a)- delta)\n",
      "    diff_plus = max((np.abs(a)- delta),0)\n",
      "\n",
      "    return sign*diff_plus\n",
      "\n",
      "\n",
      "def validate_lambda_shooting(X_train,y_train, X_validation, y_validation, initial_theta, Lambda_max):\n",
      "    '''select the lambda that minimizes the square error on the validation set'''\n",
      "\n",
      "    Lambdas = np.linspace(0.0, Lambda_max, num=50)\n",
      "    Lambdas_2 = [10**i for i in range(-6,3)]\n",
      "    losses = []\n",
      "    min_cost = 1000.0\n",
      "    min_theta  = np.zeros(d)\n",
      "    min_Lambda = 0.0\n",
      "\n",
      "    # Choose the lambda that minimizes the square loss on the validation set.\n",
      "    for Lambda in Lambdas_2:\n",
      "\n",
      "        theta_shooting = shooting_algorithm(initial_theta, X_train, y_train, Lambda)\n",
      "        new_cost = compute_loss(X_validation, y_validation, theta_shooting)\n",
      "\n",
      "        if new_cost<min_cost:\n",
      "            min_cost = new_cost\n",
      "            min_theta  = theta_shooting\n",
      "            min_Lambda = Lambda\n",
      "        print Lambda, new_cost\n",
      "\n",
      "        losses.append(new_cost)\n",
      "    print \"best theta\", min_theta\n",
      "    print \"losses\", losses\n",
      "    print \"min lambda\", min_Lambda\n",
      "    return Lambda, new_cost, Lambdas, losses\n",
      "    \n",
      "def homotopy(X_train,y_train, X_validation, y_validation, initial_theta, Lambda_max):\n",
      "    \n",
      "    Lambdas = np.linspace(0.0, Lambda_max, num=50)\n",
      "    Lambdas_2 = [10**i for i in range(3, -6 , -1)]\n",
      "    losses = []\n",
      "    min_cost = 1000.0\n",
      "    min_theta  = np.zeros(d)\n",
      "    min_Lambda = 0.0\n",
      "\n",
      "    Lambdas_3 = [10**i for i in range(-6,3)]\n",
      "    # Choose the lambda that minimizes the square loss on the validation set.\n",
      "    theta_shooting = initial_theta.copy()\n",
      "\n",
      "    for Lambda in Lambdas_3:\n",
      "        \n",
      "        theta_shooting = shooting_algorithm(theta_shooting, X_train, y_train, Lambda)\n",
      "        new_cost = compute_loss(X_validation, y_validation, theta_shooting)\n",
      "\n",
      "        if new_cost<min_cost:\n",
      "            #print \"updating\"\n",
      "            min_cost = new_cost\n",
      "            min_theta  = theta_shooting\n",
      "        print Lambda, new_cost\n",
      "\n",
      "        losses.append(new_cost)\n",
      "    print \"best theta\", min_theta\n",
      "    print \"losses\", losses\n",
      "    \n",
      "    return \n",
      "\n",
      "\n",
      "def vectorized_shooting_algorithm(initial_theta, X, y, Lambda):\n",
      "    ''' This function is a vectorized version of of the shooting_algorithm function and is meant to replace it in calculations'''\n",
      "    theta_shooting = initial_theta.copy() #ridge_theta.copy()\n",
      "    #old_theta = initial_theta + 5\n",
      "\n",
      "    #print np.linalg.norm(old_theta - theta_shooting)\n",
      "\n",
      "\n",
      "    threshold = 0.000001\n",
      "\n",
      "    #initialize loss values to ensure that while loop if entered\n",
      "    old_loss = 100000.0\n",
      "    new_loss = 0.0\n",
      "    \n",
      "    iter_counter = 0.0\n",
      "\n",
      "    D = np.dot(X.T,X)\n",
      "    E  = np.dot(X.T,y)\n",
      "\n",
      "\n",
      "    while (np.abs(old_loss - new_loss) >= threshold) and  iter_counter <5000:\n",
      "        iter_counter+=1\n",
      "    \n",
      "        for feature in range(d):\n",
      "            a_j = 2*D[feature,feature]\n",
      "            \n",
      "\n",
      "            c_j = 2*(E[feature]-np.dot(theta_shooting,D[feature]) + D[feature,feature]*theta_shooting[feature])\n",
      "            \n",
      "            theta_shooting[feature] = soft_thresholding(a = (c_j/a_j) ,delta = (Lambda/a_j))\n",
      "\n",
      "        new_loss = compute_loss(X, y, theta_shooting) + Lambda*np.linalg.norm(theta_shooting)\n",
      "\n",
      "        old_loss , new_loss = new_loss, old_loss\n",
      "    print \"final loss\", new_loss\n",
      "    return theta_shooting"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = 150 # exaples\n",
      "d = 75 # features\n",
      "\n",
      "X = make_dataset()\n",
      "true_theta = construct_true_theta()\n",
      "\n",
      "\n",
      "y = construct_target(X, true_theta, seed = 10)\n",
      "\n",
      "\n",
      "X_train, y_train, X_validation, y_validation, X_test, y_test = train_test_split(X,y)\n",
      "\n",
      "\n",
      "initial_theta = np.zeros(d)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit shooting_algorithm(initial_theta,X,y,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "final loss:  303.037867601  iterations :  308.0\n",
        "final loss: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 303.037867601  iterations :  308.0\n",
        "final loss: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 303.037867601  iterations :  308.0\n",
        "final loss: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 303.037867601  iterations :  308.0\n",
        "1 loops, best of 3: 24.9 s per loop\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "############ Question 1.1 ######################\n",
      "m = 150 # exaples\n",
      "d = 75 # features\n",
      "\n",
      "X = make_dataset()\n",
      "true_theta = construct_true_theta()\n",
      "\n",
      "\n",
      "y = construct_target(X, true_theta, seed = 10)\n",
      "\n",
      "\n",
      "X_train, y_train, X_validation, y_validation, X_test, y_test = train_test_split(X,y)\n",
      "\n",
      "\n",
      "initial_theta = np.zeros(d)\n",
      "\n",
      "############ Question 1.2 ######################\n",
      "\n",
      "\n",
      "min_cost, min_theta = find_optimal_lambda(X_train, y_train, X_validation, y_validation, initial_theta)\n",
      "\n",
      "print min_cost #0.027\n",
      "\n",
      "elements_non_zero = min_theta[min_theta>10**-3]\n",
      "\n",
      "print \"non zero elements with threshold : \",  len(elements_non_zero)\n",
      "print \"non zero elements without threshold : \", len(min_theta)\n",
      "\n",
      "\n",
      "############ Question 2 ######################\n",
      "temp= np.dot(X_train.T,(y_train - np.mean(y_train)))\n",
      "Lambda_max = 2*np.linalg.norm(temp, np.inf)\n",
      "\n",
      "\n",
      "theta_shooting = shooting_algorithm(initial_theta,  X_train, y_train, Lambda = 0)\n",
      "print \"loss\", compute_loss(X_validation, y_validation, theta_shooting) \n",
      "\n",
      "\n",
      "\n",
      "# find optimal lambda\n",
      "Lambda, new_cost, Lambdas, losses = validate_lambda_shooting(X_train,y_train, X_validation, y_validation, initial_theta, Lambda_max = 10)\n",
      "\n",
      "plt.plot(range(-6,3), losses)\n",
      "plt.title(\"Lasso Regression\")\n",
      "plt.xlabel(\"Lambda\")\n",
      "plt.ylabel(\"Validation Loss\")\n",
      "plt.savefig(\"shooting.png\")\n",
      "\n",
      "print \"*****************************\"\n",
      "\n",
      "homotopy(X_train,y_train, X_validation, y_validation, initial_theta, Lambda_max)\n",
      "\n",
      "begin1 = time.time()\n",
      "shooting_algorithm(initial_theta,  X_train, y_train, Lambda = 2)\n",
      "end1 = time.time()\n",
      "print \"shooting\", end1- begin1\n",
      "\n",
      "begin2 = time.time()\n",
      "print vectorized_shooting_algorithm(initial_theta, X_train, y_train, Lambda=2)\n",
      "end2 = time.time()\n",
      "\n",
      "print \"vectorized\", end2 - begin2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1e-09 0.0560120191062 True\n",
        "1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0559544496454 True\n",
        "1e-07"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0553921213126 True\n",
        "1e-06"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0501372917156 True\n",
        "1e-05"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0279718148521 True\n",
        "0.0001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.605622781175 True\n",
        "0.001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.38177752693 True\n",
        "0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12.8666364325 True\n",
        "0.1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20.4772335556 True\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23.8069150668 True\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 49.5247973236 True\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 139.602481567 False\n",
        "1000"
       ]
      }
     ]
    }
   ],
   "metadata": {}
  }
 ]
}