{
 "metadata": {
  "name": "",
  "signature": "sha256:d348db02ccc1af0303d5a0a5dc083d34fb2a87aabe1a0819713eaff159eaa578"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "#Machine Learning and Computational Statistics, Sprint 2015 Homework 3: SVM and Sentiment Analysis\n",
      "---\n",
      "###Charlie Guthrie\n",
      "Due Monday, Feb 23, 2015 at 4pm.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#1 Introduction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Prep\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pickle\n",
      "import random\n",
      "import collections\n",
      "from datetime import datetime\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "#pd.options.display.mpl_style = 'default'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = datetime.now()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finish = datetime.now()\n",
      "delta = finish-start\n",
      "delta.seconds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "12"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#2 The Data\n",
      "\n",
      "1. Load all the data and randomly split it into 1500 training examples and 500 test examples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def folder_list(path,label):\n",
      "    '''\n",
      "    Take path to a directory, apply the label the contained documents,\n",
      "    and return the list of documents\n",
      "    PARAMETER PATH IS THE PATH OF YOUR LOCAL FOLDER\n",
      "    Label is positive or negative\n",
      "    '''\n",
      "    filelist = os.listdir(path)\n",
      "    review = []\n",
      "    for infile in filelist:\n",
      "        file = os.path.join(path,infile)\n",
      "        r = read_data(file)\n",
      "        r.append(label)\n",
      "        review.append(r)\n",
      "    return review\n",
      "\n",
      "def read_data(file):\n",
      "    '''\n",
      "    Read each file into a list of strings. \n",
      "    Example:\n",
      "    [\"it's\", 'a', 'curious', 'thing', \"i've\", 'found', 'that', 'when', 'willis', 'is', 'not', 'called', 'on', \n",
      "    ...'to', 'carry', 'the', 'whole', 'movie', \"he's\", 'much', 'better', 'and', 'so', 'is', 'the', 'movie']\n",
      "    '''\n",
      "    f = open(file)\n",
      "    lines = f.read().split(' ')\n",
      "    symbols = '${}()[].,:;+-*/&|<>=~\"_`\\' '\n",
      "    words = map(lambda Element: Element.translate(None, symbols).strip(), lines)\n",
      "    words = filter(None, words)\n",
      "    return words\n",
      "    \n",
      "def train_test_split(data,pivot_index):\n",
      "    '''\n",
      "    split list of documents into training and test sets\n",
      "    '''\n",
      "    random.shuffle(data)\n",
      "    train = data[:pivot_index]\n",
      "    test = data[pivot_index:]\n",
      "    assert len(train)==pivot_index, \"Training set is not proper length\"\n",
      "    return train,test\n",
      "\n",
      "def load_data():\n",
      "    '''\n",
      "    pos_path is where you save positive review data.\n",
      "    neg_path is where you save negative review data.\n",
      "    '''\n",
      "    home_dir = os.getcwd()\n",
      "    pos_path = os.path.join(home_dir,\"data/pos\")\n",
      "    neg_path = os.path.join(home_dir,\"data/neg\")\n",
      "\n",
      "    pos_review = folder_list(pos_path,1)\n",
      "    neg_review = folder_list(neg_path,-1)\n",
      "\n",
      "    review = pos_review + neg_review\n",
      "    return train_test_split(review,1500)\n",
      "\n",
      "train,test = load_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "#3 Sparse Representations\n",
      "1. Write a function that converts an example (e.g. list of words) into a sparse bag-of-words representation.  \n",
      ">See next cell\n",
      "\n",
      "1. Write a version of `generic_gradient_checker` from Homework 1 that works with sparse vectors represented as dict types.  Since we'll be using it for stochastic methods, it should take a single $(x,y)$ pair, rather than the entire dataset.  Be sure to use the dotProduct and increment primitives we provide, or make your own. \n",
      ">See next cell"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#############\n",
      "#Question 3.1\n",
      "\n",
      "def lists2bags(lists):\n",
      "    bags = []\n",
      "    labels = []\n",
      "    for review in lists:\n",
      "        #don't include the review's label\n",
      "        bag = collections.Counter(review[:-1])\n",
      "        bags.append(bag)\n",
      "        labels.append(review[-1])\n",
      "    return bags,labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_corpus_words(X):\n",
      "    '''count words in entire corpus'''\n",
      "    c = collections.Counter()\n",
      "    for review in X:\n",
      "        c.update(review)\n",
      "    return c\n",
      "\n",
      "def filter_w(min_occurrences):\n",
      "    '''\n",
      "    remove stopwords and single instances\n",
      "    Stopwords list from http://www.ranks.nl/stopwords\n",
      "    initialize w to zero\n",
      "    '''\n",
      "    full_dictionary = count_corpus_words(X)\n",
      "    f = open('stopwords.txt')\n",
      "    stopwords = f.read().split(',')\n",
      "    \n",
      "    w={}\n",
      "    for k, v in full_dictionary.items():\n",
      "        if v>min_occurrences and k not in stopwords:\n",
      "            w[k]=0\n",
      "    return w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#############\n",
      "#Question 3.2\n",
      "\n",
      "def dotProduct(d1, d2):\n",
      "    \"\"\"\n",
      "    @param dict d1: a feature vector represented by a mapping from a feature (string) to a weight (float).\n",
      "    @param dict d2: same as d1\n",
      "    @return float: the dot product between d1 and d2\n",
      "    \"\"\"\n",
      "    if len(d1) < len(d2):\n",
      "        return dotProduct(d2, d1)\n",
      "    else:\n",
      "        return sum(d1.get(f, 0) * v for f, v in d2.items())\n",
      "\n",
      "def increment(d1, scale, d2):\n",
      "    \"\"\"\n",
      "    MODIFIED: Does not add keys to d1\n",
      "    Implements d1 += scale * d2 for sparse vectors.\n",
      "    @param dict d1: the feature vector which is mutated.\n",
      "    @param float scale\n",
      "    @param dict d2: a feature vector.\n",
      "    \"\"\"\n",
      "    for f, v in d2.items():\n",
      "        current_val = d1.get(f)\n",
      "        d1[f] = (current_val + v * scale) if current_val is not None\n",
      "\n",
      "def svm_stochastic_cost(x,y,w,Lambda):\n",
      "    \"\"\"\n",
      "    Given a set of X, y, theta, compute the square loss for predicting y with X*theta\n",
      "    \n",
      "    Args:\n",
      "        x - sparse feature dict\n",
      "        y - the label vector, 1D numpy array of size (num_instances)\n",
      "        w - sparse parameter dict\n",
      "        Lambda - regularization hyperparameter\n",
      "    \n",
      "    Returns:\n",
      "        loss - the square loss, scalar\n",
      "    \"\"\"        \n",
      "    return Lambda/2*dotProduct(w,w) + max(0,1-y*dotProduct(w,x))\n",
      "    \n",
      "def grad_checker(x, y, w, Lambda, obj_func,grad_func,epsilon=0.01, tolerance=1e-4): \n",
      "    \"\"\"Implement Gradient Checker\n",
      "    Check that the function compute_square_loss_gradient returns the\n",
      "    correct gradient for the given x, y, and theta.\n",
      "\n",
      "    Let d be the number of features. Here we numerically estimate the\n",
      "    gradient by approximating the directional derivative in each of\n",
      "    the d coordinate directions: \n",
      "    (e_1 = (1,0,0,...,0), e_2 = (0,1,0,...,0), ..., e_d = (0,...,0,1) \n",
      "\n",
      "    The approximation for the directional derivative of J at the point\n",
      "    theta in the direction e_i is given by: \n",
      "    ( J(theta + epsilon * e_i) - J(theta - epsilon * e_i) ) / (2*epsilon).\n",
      "\n",
      "    We then look at the Euclidean distance between the gradient\n",
      "    computed using this approximation and the gradient computed by\n",
      "    compute_square_loss_gradient(X, y, theta).  If the Euclidean\n",
      "    distance exceeds tolerance, we say the gradient is incorrect.\n",
      "\n",
      "    Args:\n",
      "        x - sparse feature dict\n",
      "        y - the label vector, 1D numpy array of size (num_instances)\n",
      "        w - sparse parameter dict\n",
      "        Lambda - regularization hyperparameter\n",
      "        epsilon - the epsilon used in approximation\n",
      "        tolerance - the tolerance error\n",
      "    \n",
      "    Return:\n",
      "        A boolean value indicate whether the gradient is correct or not\n",
      "\n",
      "    \"\"\" \n",
      "    \n",
      "    true_gradient = grad_func(x, y, w,Lambda) #the true gradient\n",
      "    approx_grad = {} #Initialize the gradient we approximate\n",
      "    dist = 0\n",
      "    for key in w:\n",
      "        w_plus = w.copy()\n",
      "        w_minus = w.copy()\n",
      "        w_plus[key]+= -epsilon\n",
      "        w_minus[key]+= epsilon\n",
      "    \n",
      "        approx_grad[key] = (obj_func(x,y,w_plus,Lambda) - obj_func(x,y,w_minus))*1.0 / (2.0*epsilon)\n",
      "        dist+=(approx_grad[key] - true_gradient[key])**2\n",
      "    \n",
      "    correct_grad = dist<tolerance\n",
      "    assert correct_grad, \"Gradient bad: dist %s is greater than tolerance %s\" % (dist,tolerance)\n",
      "    return correct_grad"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#4 Support Vector Machine via Pegasos\n",
      "1. [Written] Compute a subgradient for the \"stochastic\" SVM objective, which assumes a single training point.  Show that if your step size rule is $\\eta_t = 1/(\\lambda t)$, then the corresponding SGD update is the same as given in the pseudocode.  \n",
      "> The objective function $J(w)$ for example $j$ is as follows:\n",
      ">\n",
      "$$J(w) = \\begin{cases}\n",
      "1-y_jw^Tx_j + \\frac{\\lambda}{2}||w||^2 & \\text{if $y_jw^Tx_j<1$}; \\\\\n",
      "\\frac{\\lambda}{2}||w||^2 & \\text{otherwise}.\n",
      "\\end{cases}$$\n",
      ">\n",
      ">Taking the gradients of both parts with respect to $w$, then:\n",
      ">\n",
      "$$\\nabla J(w) = \\begin{cases}\n",
      "\\lambda w - x_jy_j & \\text{if $y_jw^Tx_j<1$}; \\\\\n",
      "\\lambda w & \\text{otherwise}.\n",
      "\\end{cases}$$\n",
      ">\n",
      ">Updating $w$ according to the equation $w_{t+1}=w_t + \\eta_t\\nabla J(w_t)$, where $\\eta_t$ is step size, we have:\n",
      ">\n",
      "$$w_{t+1} = \\begin{cases}\n",
      "(1-\\eta_t\\lambda)w_t + \\eta_ty_jx_j & \\text{if $y_jw_t^Tx_j<1$}; \\\\\n",
      "(1-\\eta_t\\lambda)w_t & \\text{otherwise}.\n",
      "\\end{cases}$$\n",
      "\n",
      "2. Implement the Pegasos algorithm to run on a sparse data representation. The output should be a sparse weight vector $w$. [As should be your habit, please check your gradient using generic gradient checker while you are in the testing phase. That will be our first question if you ask for help debugging. Once you\u2019re convinced it works, take it out so it doesn\u2019t slow down your code.]\n",
      ">See next cell\n",
      "\n",
      "3. Write a function that takes the sparse weight vector $w$ and a collection of $(x,y)$ pairs, and returns the percent error when predicting $y$ using sign$(w^Tx)$ (that is, report the 0-1 loss).\n",
      ">See next cell\n",
      "\n",
      "4. Using the bag-of-words feature representation described above, search for the regularization parameter that gives the minimal percent error on your test set. A good search strategy is to start with a set of lambdas spanning a broad range of orders of magnitude. Then, continue to zoom in until you\u2019re convinced that additional search will not significantly improve your test performance. Once you have a sense of the general range of regularization parameters that give good results, you do not have to search over orders of magnitude every time you change something (such as adding new feature).\n",
      ">See next cell\n",
      "\n",
      "5. Recall that the \u201cscore\u201d is the value of the prediction $f(x) = w^Tx$. We like to think that the magnitude of the score represents the confidence of the prediction. This is something we can directly verify or refute. Break the predictions into groups based on the score (you can play with the size of the groups to get a result you think is informative). For each group, examine the percentage error. You can make a table or graph. Summarize the results. Is there a correlation between higher magnitude scores and accuracy?\n",
      ">See next cell"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#############\n",
      "#Question 4.2\n",
      "\n",
      "def pegasos(X,y,Lambda=1,max_epochs=10):\n",
      "    t1 = datetime.now()\n",
      "    w=filter_w(1)\n",
      "    print len(w)\n",
      "    t=epoch=0\n",
      "    m=len(X)\n",
      "    \n",
      "    while epoch<max_epochs:\n",
      "        print \"epoch\",epoch\n",
      "        for j in range(1,m):\n",
      "            t+=1\n",
      "            eta = 1.0/(t*Lambda)\n",
      "            if y[j]*dotProduct(w,X[j])<1:\n",
      "                increment(w,-eta*Lambda,w)\n",
      "                increment(w,eta*y[j],X[j])\n",
      "            else:\n",
      "                increment(w,-eta*Lambda,w)\n",
      "        epoch+=1\n",
      "        \n",
      "    t2 = datetime.now()\n",
      "    print \"Time taken: %i seconds\" %(t2-t1).seconds\n",
      "    return w\n",
      "\n",
      "X,y=lists2bags(train)\n",
      "X_test,y_test=lists2bags(test)\n",
      "\n",
      "X = X[:100]\n",
      "y = y[:100]\n",
      "\n",
      "#w = pegasos(X,y,1,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#############\n",
      "#Question 4.3\n",
      "def get_pct_error(X,y,w):\n",
      "    num_correct=0\n",
      "    for i in range(len(X)):\n",
      "        yhat = np.sign(dotProduct(w,X[i]))\n",
      "        num_correct+=max(y[i]*yhat,0)        \n",
      "    return 1-float(num_correct)/len(y)\n",
      "\n",
      "get_pct_error(X_test,y_test,w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 221,
       "text": [
        "0.264"
       ]
      }
     ],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#############\n",
      "#Question 4.4\n",
      "def Lambda_search(opt_func):\n",
      "    \"\"\"\n",
      "    Runs an optimization function on a training set with a variety of \n",
      "    regularization hyperparameters Lambda.  \n",
      "    Selects the lambda that minimizes square error on the validation set.\n",
      "    Plots validation error vs. Lambda\n",
      "    Prints selected lambda along with corresponding test error.\n",
      "    \"\"\"\n",
      "    #loop through array of lambdas\n",
      "    t=0\n",
      "    Lambdas=[]\n",
      "    loss_hist=[]\n",
      "    print \"Starting Loop\"\n",
      "    for i in range(-3,2):\n",
      "        Lambda = 10**i\n",
      "        print \"Lambda\",Lambda\n",
      "        Lambdas.append(Lambda)\n",
      "        w=opt_func(X,y,Lambda)\n",
      "        loss=get_pct_error(X_test,y_test,w)\n",
      "        loss_hist.append(loss)\n",
      "        \n",
      "        if t==0 or loss<=loss_opt:\n",
      "            loss_opt = loss\n",
      "            lambda_opt = Lambda\n",
      "            w_opt = w.copy()\n",
      "        t=t+1\n",
      "    \n",
      "    print \"Best Lambda:\",lambda_opt\n",
      "    print \"Square Loss on Test Data:\", loss_opt\n",
      "    \n",
      "    return w_opt,Lambdas,loss_hist\n",
      "\n",
      "w_opt,Lambdas,loss_hist=Lambda_search(pegasos)\n",
      "plt.plot(Lambdas,loss_hist)\n",
      "plt.xlabel('Lambda')\n",
      "plt.ylabel('Pct. Error')\n",
      "plt.xscale('log')\n",
      "plt.title('Pct. Error vs. Lambda')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting Loop\n",
        "Lambda 0.001\n",
        "4389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 0\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Time taken: 13 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Lambda"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.01\n",
        "4389\n",
        "epoch 0\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Time taken: 11 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Lambda"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "4389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 0\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Time taken: 13 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Lambda"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "4389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 0\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Time taken: 14 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Lambda"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "4389\n",
        "epoch 0\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "epoch"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Time taken: 14 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Best Lambda:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Square Loss on Test Data: 0.288\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEeCAYAAAByoJkBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108bc7290>"
       ]
      }
     ],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#############\n",
      "#Question 4.5\n",
      "def discretize_score(X,y,w,bins=10):\n",
      "    scores=[]\n",
      "    for i in range(len(X)):\n",
      "        score = dotProduct(w,X[i])\n",
      "        scores.append(score)\n",
      "    score_df=pd.DataFrame(zip(scores,y))\n",
      "    score_df.columns=('score','label')\n",
      "    score_df['prediction']=np.sign(score_df['score'])\n",
      "    score_df = score_df.sort('score')\n",
      "    #sorted_scores = np.sort(score_array,axis=0)\n",
      "\n",
      "    index=0\n",
      "    score_df['bin']=0\n",
      "    summary = pd.DataFrame(columns=('avg_score','pct_error'))\n",
      "    chunk = ss.shape[0]/bins \n",
      "    \n",
      "    #for each bin...\n",
      "    for i in range(bins):\n",
      "        score_df['bin'].iloc[index:index+chunk]=i\n",
      "        temp = score_df.iloc[index:index+chunk]\n",
      "        assert temp.shape[0]==score_df.shape[0]/bins,\"Temporary DF is wrong size\"\n",
      "        #record avg score\n",
      "        summary.loc[i,'avg_score']=temp['score'].mean()\n",
      "\n",
      "        #get pct error\n",
      "        pct_error = float(temp[temp.prediction != temp.label].shape[0])/temp.shape[0]\n",
      "        summary.loc[i,'pct_error']=pct_error\n",
      "        index+=chunk\n",
      "    return summary\n",
      "score_summary=discretize_score(X_test,y_test,w_opt)\n",
      "\n",
      "score_summary.plot(x='avg_score',y='pct_error')\n",
      "plt.xlabel('Average Bin Score')\n",
      "plt.ylabel('Pct. Error')\n",
      "score_summary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>avg_score</th>\n",
        "      <th>pct_error</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  -2.430081</td>\n",
        "      <td>  0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  -1.242586</td>\n",
        "      <td> 0.16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> -0.7451111</td>\n",
        "      <td> 0.32</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> -0.3607475</td>\n",
        "      <td> 0.26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.05874747</td>\n",
        "      <td> 0.52</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>  0.4418182</td>\n",
        "      <td> 0.48</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>  0.7878586</td>\n",
        "      <td> 0.44</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>   1.278909</td>\n",
        "      <td> 0.24</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>   1.952505</td>\n",
        "      <td> 0.18</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>   3.576485</td>\n",
        "      <td> 0.08</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 301,
       "text": [
        "    avg_score pct_error\n",
        "0   -2.430081       0.2\n",
        "1   -1.242586      0.16\n",
        "2  -0.7451111      0.32\n",
        "3  -0.3607475      0.26\n",
        "4  0.05874747      0.52\n",
        "5   0.4418182      0.48\n",
        "6   0.7878586      0.44\n",
        "7    1.278909      0.24\n",
        "8    1.952505      0.18\n",
        "9    3.576485      0.08"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109d7e850>"
       ]
      }
     ],
     "prompt_number": 301
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#5 Error Analysis\n",
      "The natural language processing domain is particularly nice in that one can often interpret why a model has performed well or poorly on a specific example, and sometimes it is not very difficult to come up with ideas for new features that might help fix a problem. The first step in this process is to look closely at the errors that our model makes.\n",
      "\n",
      "1. Choose some examples that the model got wrong. List the features that contributed most heavily to the descision (e.g. rank them by $|w_ix_i|$), along with $x_i, w_i, xw_i$. Do you understand why the model was incorrect? Can you think of a new feature that might be able to fix the issue? Include a short analysis for at least 3 incorrect examples."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#6 Features\n",
      "For a problem like this, the features you use are far more important than the learning model you choose. Whenever you enter a new problem domain, one of your first orders of business is to beg, borrow, or steal the best features you can find. This means looking at any relevant published work and seeing what they\u2019ve used. Maybe it means asking a colleague what features they use. But even- tually you\u2019ll need to engineer new features that help in your particular situation. To get ideas for this dataset, you might check the discussion board on this Kaggle competition, which is using a very similar dataset https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews. There are also a very large number of academic research papers on sentiment analysis that you can look at for ideas.\n",
      "\n",
      "1.  Based on your error analysis, or on some idea you have, find a new feature (or group of features) that improve your test performance. Describe the features and what kind of improvement they give. At this point, it\u2019s important to consider the standard errors $(\\sqrt{\udbff\udc05p(1 \u2212 p)/n})$ on your performance estimates, to know whether the improvement is statistically significant.\n",
      ">TODO\n",
      "\n",
      "2. [Optional] Try to get the best performance possible by generating lots of new features, chang- ing the pre-processing, or any other method you want, so long as you are using the same core SVM model. Describe what you tried, and how much improvement each thing brought to the model. To get you thinking on features, here are some basic ideas of varying quality: 1) how many words are in the review? 2) How many \u201cnegative\u201d words are there? (You\u2019d have to construct or find a list of negative words.) 3) Word n-gram features: Instead of single-word features, you can make every pair of consecutive words a feature. 4) Character n-gram features: Ignore word boundaries and make every sequence of n characters into a feature (this will be a lot). 5) Adding an extra feature whenever a word is preceded by \u201cnot\u201d. For example \u201cnot amazing\u201d becomes its own feature. 6) Do we really need to eliminate those funny characters in the data loading phase? Might there be useful signal there? 7) Use tf-idf instead of raw word counts. The tf-idf is calculated as \n",
      "$$\\textrm{tfidf}(f_i) = \\frac{FF_i}{log(DF_i)}$$\n",
      "where $F F_i$ is the feature frequency of feature $f_i$ and $DF_i$ is the number of document containing $f_i$. In this way we increase the weight of rare words. Sometimes this scheme helps, sometimes it makes things worse. You could try using both! [Extra credit points will be awarded in proportion to how much improvement you achieve.]\n",
      ">TODO if there's time"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#7 Feedback (not graded)\n",
      "1. Approximately how long did it take to complete this assignment?\n",
      ">Monday: 4 hours\n",
      ">Tuesday: 8 hours\n",
      ">Wednesday: 3 hours\n",
      "\n",
      "2. Did you find the Python programming challenging (in particular, converting your code to use sparse representations)?\n",
      ">TODO\n",
      "\n",
      "3. Any other feedback?\n",
      ">TODO"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}